{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9ee09224",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Lab II\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9695a453-bbef-4e1a-9457-4f88b004f88d",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef05d0d-f517-44ea-92fa-a21f57594de3",
   "metadata": {},
   "source": [
    "**What is the lab about**?\n",
    "\n",
    "This lab provides a practical overview of how satellite image embeddings can be used as a general-purpose spatial representation.\n",
    "\n",
    "The lab begins with unsupervised analysis, where participants use embeddings to explore and structure geographic space without predefined labels. This demonstrates how embeddings support exploratory analysis and place-based typologies. The same embeddings are then reused in a predictive context, showing how a single representation can support multiple analytical tasks without rebuilding the feature pipeline.\n",
    "\n",
    "The emphasis throughout is on reusability and judgement:\n",
    "\n",
    "* how embeddings enable faster exploration.\n",
    "* how they integrate into standard analytical workflows, and\n",
    "* when they meaningfully improve predictive performance.\n",
    "  \n",
    "The lab is not about training complex models, but about understanding how and when embeddings add value as spatial evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71ae23-450a-4cd3-bade-9443a6f80ebe",
   "metadata": {},
   "source": [
    "# Learning outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a025adc2-a92a-4498-9a96-cea5cd8e8e2f",
   "metadata": {},
   "source": [
    "By the end of the lab, participants will be able to:\n",
    "\n",
    "- Interpret satellite image embeddings as spatial representations.\n",
    "- Build and evaluate unsupervised place typologies.\n",
    "- Build and evauluate predictive models using embeddings.\n",
    "- Judge when embeddings improve geospatial evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c1a4e-d3e4-4d31-846c-9c66be14211f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627c843-e5c2-4646-bf72-5dfb12c06aa1",
   "metadata": {},
   "source": [
    "#### Embedding data\n",
    "\n",
    "- Google satellite image embedding data for London (2024).\n",
    "- Embeddings are aggregated to the Lower-layer Super Output Area (LSOA) level using the mean value of each embedding dimension.\n",
    "- The final dataset contains 64 embedding variables (A00_mean to A63_mean) and is provided as a GeoPackage:\n",
    "  `uk_lsoa_london_embeds_2024.gpkg`\n",
    "\n",
    "\n",
    "#### Socio-demographic data\n",
    "\n",
    "- **Index of Multiple Deprivation (IMD)**\n",
    "  - The Index of Multiple Deprivation (IMD) 2025 for England provides a relative measure of deprivation across 32,844 Lower-layer Super Output Areas (LSOAs).\n",
    "  - Deprivation is reported in deciles, representing 10% bands from most to least deprived.\n",
    "  - Data are available from the Ministry of Housing, Communities and Local Government GeoPortal:\n",
    "    https://communitiesopendata-communities.hub.arcgis.com/\n",
    "\n",
    "\n",
    "- **Socio-economic and population characteristics**\n",
    "  - Percentage of the population aged 16 years and over with no educational qualifications.\n",
    "  - Percentage of the population reporting bad or very bad health.\n",
    "  - Population density (persons per km²).\n",
    "  - Percentage of single-parent households.\n",
    "  - Data sourced from the 2021 Census via NOMIS:\n",
    "    https://www.nomisweb.co.uk/sources/census_2021_bulk\n",
    "\n",
    "- Both sets of data have been linked by their LSOA id and placed into 'Socioeconomic.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccd0799-cf78-4afc-83d0-a1f8fbeda33a",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "Before working with the data, a number of Python libraries are required to support data handling, spatial analysis, and modelling tasks in this lab.\n",
    "\n",
    "These libraries provide functionality for:\n",
    "\n",
    "- reading and manipulating tabular and spatial data.\n",
    "- performing numerical and statistical operations.\n",
    "- visualising spatial patterns, and\n",
    "- applying clustering and predictive models.\n",
    "\n",
    "All code in this lab assumes that these libraries are available in the working environment and correctly imported before proceeding to the analytical steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332898e-8e9d-47cd-9224-1448ac039be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import for a geospatial data science workflow combining spatial analysis,\n",
    "machine learning, and visualisation.\n",
    "\"\"\"\n",
    "\n",
    "# Spatial data handling\n",
    "import geopandas as gpd          # Vector GIS data, geometry operations, CRS handling\n",
    "import pandas as pd              # Tabular data manipulation and analysis\n",
    "\n",
    "# Numerical computing\n",
    "import numpy as np               # Numerical operations and array-based computing\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt  # Static plots and figures\n",
    "\n",
    "# Unsupervised learning\n",
    "from sklearn.cluster import KMeans           # Clustering into place typologies\n",
    "\n",
    "# Supervised learning utilities\n",
    "from sklearn.model_selection import train_test_split  # Train/test data splitting\n",
    "\n",
    "# Supervised models\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "# Tree-based ensemble models for regression and classification\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score  \n",
    "# Performance metrics for regression and classification\n",
    "\n",
    "# Mapping and basemaps\n",
    "import contextily as cx          # Basemaps for GeoPandas plots\n",
    "import folium                    # Interactive web-based maps\n",
    "from folium.features import DivIcon # Custom text/HTML map markers\n",
    "\n",
    "# Utilities\n",
    "import re                        # Regular expressions for string processing\n",
    "from IPython.display import HTML, display  # Rich HTML output in notebooks\n",
    "import uuid                      # Unique identifiers for map elements or outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3802b258-7055-4711-88d0-7556a5d7320c",
   "metadata": {},
   "source": [
    "# Functions\n",
    "These are reusable blocks of code that perform a specific task throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc5ae3-26fb-4583-a2ec-3cc80be17b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "\"\"\"\n",
    "Utility functions for spatial clustering and visualisation of LSOA-level\n",
    "satellite image embeddings.\n",
    "\n",
    "Functions include:\n",
    "- Filtering to identifier/embedding/geometry fields\n",
    "- K-means clustering in embedding space\n",
    "- Static and interactive mapping\n",
    "- Selecting and mapping LSOAs closest to a cluster centroid\n",
    "\"\"\"\n",
    "\n",
    "def filter_table(gdf):\n",
    "    \"\"\"\n",
    "    Filter a GeoDataFrame to identifier fields, embedding variables, and geometry.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        Input GeoDataFrame containing identifiers, embedding variables, and geometry.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        Filtered GeoDataFrame containing predefined columns (where present).\n",
    "    \"\"\"\n",
    "    columns_to_keep = [\n",
    "        \"data_zone_code\", \"country\", \"LSOA21CD\", \"LSOA21NM\",\n",
    "        \"A00_mean\", \"A01_mean\", \"A02_mean\", \"A03_mean\", \"A04_mean\",\n",
    "        \"A05_mean\", \"A06_mean\", \"A07_mean\", \"A08_mean\", \"A09_mean\",\n",
    "        \"A10_mean\", \"A11_mean\", \"A12_mean\", \"A13_mean\", \"A14_mean\",\n",
    "        \"A15_mean\", \"A16_mean\", \"A17_mean\", \"A18_mean\", \"A19_mean\",\n",
    "        \"A20_mean\", \"A21_mean\", \"A22_mean\", \"A23_mean\", \"A24_mean\",\n",
    "        \"A25_mean\", \"A26_mean\", \"A27_mean\", \"A28_mean\", \"A29_mean\",\n",
    "        \"A30_mean\", \"A31_mean\", \"A32_mean\", \"A33_mean\", \"A34_mean\",\n",
    "        \"A35_mean\", \"A36_mean\", \"A37_mean\", \"A38_mean\", \"A39_mean\",\n",
    "        \"A40_mean\", \"A41_mean\", \"A42_mean\", \"A43_mean\", \"A44_mean\",\n",
    "        \"A45_mean\", \"A46_mean\", \"A47_mean\", \"A48_mean\", \"A49_mean\",\n",
    "        \"A50_mean\", \"A51_mean\", \"A52_mean\", \"A53_mean\", \"A54_mean\",\n",
    "        \"A55_mean\", \"A56_mean\", \"A57_mean\", \"A58_mean\", \"A59_mean\",\n",
    "        \"A60_mean\", \"A61_mean\", \"A62_mean\", \"A63_mean\", \"geometry\",\n",
    "    ]\n",
    "    cols = [c for c in columns_to_keep if c in gdf.columns]\n",
    "    return gdf[cols]\n",
    "\n",
    "\n",
    "def kmeans_clustering(gdf, k, feature_suffix=\"_mean\", random_state=42):\n",
    "    \"\"\"\n",
    "    Cluster embedding variables using k-means.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        Input GeoDataFrame containing embedding variables.\n",
    "    k : int\n",
    "        Number of clusters.\n",
    "    feature_suffix : str, optional\n",
    "        Suffix used to identify feature columns. Default is ``\"_mean\"``.\n",
    "    random_state : int, optional\n",
    "        Random seed for reproducibility. Default is 42.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        Copy of `gdf` with an added ``\"cluster\"`` column.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If no feature columns are found that match `feature_suffix`.\n",
    "    \"\"\"\n",
    "    feature_cols = [c for c in gdf.columns if c.endswith(feature_suffix)]\n",
    "    if not feature_cols:\n",
    "        raise ValueError(f\"No feature columns found ending with '{feature_suffix}'.\")\n",
    "\n",
    "    X = gdf[feature_cols].to_numpy(dtype=float)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=int(k), random_state=random_state)\n",
    "\n",
    "    gdf_out = gdf.copy()\n",
    "    gdf_out[\"cluster\"] = kmeans.fit_predict(X)\n",
    "    return gdf_out\n",
    "\n",
    "\n",
    "def show_cluster_labels(gdf, cluster_col=\"cluster\"):\n",
    "    \"\"\"\n",
    "    Print unique cluster labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing cluster labels.\n",
    "    cluster_col : str, optional\n",
    "        Name of the cluster label column. Default is ``\"cluster\"``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints labels to standard output.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `cluster_col` is not present in `gdf`.\n",
    "    \"\"\"\n",
    "    if cluster_col not in gdf.columns:\n",
    "        raise ValueError(f\"'{cluster_col}' column not found.\")\n",
    "    labels = sorted(pd.unique(gdf[cluster_col]))\n",
    "    print(\"Your clusters are:\", \", \".join(map(str, labels)))\n",
    "\n",
    "def plot_simple_map(\n",
    "    gdf,\n",
    "    cluster_col=\"cluster\",\n",
    "    title=\"Unsupervised Classification of Places in London\",\n",
    "    figsize=(8, 8),\n",
    "    legend=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot spatial clusters with a basemap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing geometries and cluster labels.\n",
    "    cluster_col : str, optional\n",
    "        Name of the cluster label column. Default is ``\"cluster\"``.\n",
    "    title : str, optional\n",
    "        Plot title. Default is ``\"Unsupervised Classification of Places in London\"``.\n",
    "    figsize : tuple of int, optional\n",
    "        Figure size in inches. Default is ``(8, 8)``.\n",
    "    legend : bool, optional\n",
    "        Whether to show a legend. Default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.axes.Axes\n",
    "        Axes containing the map.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    `contextily` basemaps are added using the CRS of `gdf`. If tiles do not align,\n",
    "    ensure `gdf` is projected appropriately (commonly EPSG:3857).\n",
    "    \"\"\"\n",
    "    if cluster_col not in gdf.columns:\n",
    "        raise ValueError(f\"'{cluster_col}' column not found.\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    gdf.plot(column=cluster_col, categorical=True, legend=legend, ax=ax)\n",
    "    cx.add_basemap(ax, crs=gdf.crs)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c213fc-b732-40eb-8122-5996e2d8e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "def parse_reference_points(text):\n",
    "    \"\"\"\n",
    "    Parse reference points from a simple text format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str or None\n",
    "        Multiline string where each line is formatted as:\n",
    "        ``\"Name\", latitude, longitude``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        List of dictionaries with keys ``\"name\"``, ``\"lat\"``, and ``\"lon\"``.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If any line does not contain exactly three comma-separated values.\n",
    "    \"\"\"\n",
    "    reference_points = []\n",
    "    if not text:\n",
    "        return reference_points\n",
    "\n",
    "    for line in text.strip().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        parts = [p.strip() for p in line.split(\",\")]\n",
    "        if len(parts) != 3:\n",
    "            raise ValueError(f\"Invalid line format: {line}\")\n",
    "\n",
    "        reference_points.append(\n",
    "            {\n",
    "                \"name\": parts[0].strip('\"').strip(\"'\"),\n",
    "                \"lat\": float(parts[1]),\n",
    "                \"lon\": float(parts[2]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return reference_points\n",
    "\n",
    "\n",
    "def make_webmap_general(\n",
    "    focus_gdf,\n",
    "    focus_col=None,\n",
    "    focus_name=\"Focus\",\n",
    "    focus_tooltip_cols=(),\n",
    "    focus_categorical=True,\n",
    "    focus_legend=True,\n",
    "    focus_cmap=\"Set1\",\n",
    "    focus_style_kwds=None,\n",
    "    context_gdf=None,\n",
    "    context_name=\"Context\",\n",
    "    context_style_kwds=None,\n",
    "    POIs=None,\n",
    "    layer_control_collapsed=False,\n",
    "    fit_to=\"focus\",  # \"focus\" or \"all\"\n",
    "    zoom_start=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a general interactive folium map with an optional context layer and\n",
    "    an optional focus layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    focus_gdf : geopandas.GeoDataFrame\n",
    "        GeoDataFrame to display as the main (top) layer.\n",
    "    focus_col : str or None, optional\n",
    "        Column used to colour polygons in the focus layer. If None, polygons are\n",
    "        drawn with a single style. Default is None.\n",
    "    focus_name : str, optional\n",
    "        Layer name for the focus layer. Default is \"Focus\".\n",
    "    focus_tooltip_cols : tuple of str, optional\n",
    "        Columns shown in tooltip for the focus layer. Default is ().\n",
    "    focus_categorical : bool, optional\n",
    "        Whether the focus_col is categorical (passed to explore). Default is True.\n",
    "    focus_legend : bool, optional\n",
    "        Whether to show a legend for the focus layer. Default is True.\n",
    "    focus_cmap : str, optional\n",
    "        Matplotlib/GeoPandas colour map name. Default is \"Set1\".\n",
    "    focus_style_kwds : dict or None, optional\n",
    "        Style kwargs for the focus layer (fillOpacity, weight, color, etc.).\n",
    "    context_gdf : geopandas.GeoDataFrame or None, optional\n",
    "        Optional background context layer displayed underneath. Default is None.\n",
    "    context_name : str, optional\n",
    "        Layer name for the context layer. Default is \"Context\".\n",
    "    context_style_kwds : dict or None, optional\n",
    "        Style kwargs for the context layer.\n",
    "    POIs : str or None, optional\n",
    "        Multiline string of reference points parsed by `parse_reference_points`.\n",
    "    layer_control_collapsed : bool, optional\n",
    "        Whether the layer control is collapsed. Default is False.\n",
    "    fit_to : {\"focus\", \"all\"}, optional\n",
    "        Fit bounds to the focus layer only, or to the union of context+focus.\n",
    "        Default is \"focus\".\n",
    "    zoom_start : int, optional\n",
    "        Initial zoom level (will be overridden by fit_bounds). Default is 10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    folium.Map\n",
    "        Interactive map.\n",
    "    \"\"\"\n",
    "    if focus_gdf is None or len(focus_gdf) == 0:\n",
    "        raise ValueError(\"focus_gdf must be a non-empty GeoDataFrame.\")\n",
    "\n",
    "    # Defaults\n",
    "    if focus_style_kwds is None:\n",
    "        focus_style_kwds = {\"fillOpacity\": 0.6, \"weight\": 0.8, \"color\": \"black\"}\n",
    "    if context_style_kwds is None:\n",
    "        context_style_kwds = {\"fillOpacity\": 0.05, \"opacity\": 0.6, \"weight\": 0.6, \"color\": \"grey\"}\n",
    "\n",
    "    # Reproject to WGS84 for folium\n",
    "    focus_wgs84 = focus_gdf.to_crs(epsg=4326)\n",
    "    if context_gdf is not None:\n",
    "        context_wgs84 = context_gdf.to_crs(epsg=4326)\n",
    "    else:\n",
    "        context_wgs84 = None\n",
    "\n",
    "    # Centre map using focus bounds\n",
    "    minx, miny, maxx, maxy = focus_wgs84.total_bounds\n",
    "    centre = [(miny + maxy) / 2, (minx + maxx) / 2]\n",
    "    m = folium.Map(location=centre, zoom_start=zoom_start, tiles=None)\n",
    "\n",
    "    # Basemaps\n",
    "    folium.TileLayer(\"CartoDB positron\", name=\"CartoDB Positron\", overlay=False, control=True, show=True).add_to(m)\n",
    "    folium.TileLayer(\"Esri.WorldImagery\", name=\"Satellite (Esri)\", overlay=False, control=True, show=False).add_to(m)\n",
    "\n",
    "    # Context layer (underneath)\n",
    "    if context_wgs84 is not None and len(context_wgs84) > 0:\n",
    "        context_wgs84.explore(\n",
    "            m=m,\n",
    "            name=context_name,\n",
    "            tooltip=False,\n",
    "            legend=False,\n",
    "            show=True,\n",
    "            style_kwds=context_style_kwds,\n",
    "        )\n",
    "\n",
    "    # Focus layer (on top)\n",
    "    tooltip = [c for c in focus_tooltip_cols if c in focus_wgs84.columns]\n",
    "\n",
    "    if focus_col is None:\n",
    "        # Single-style polygons (no colouring)\n",
    "        focus_wgs84.explore(\n",
    "            m=m,\n",
    "            name=focus_name,\n",
    "            tooltip=tooltip if tooltip else False,\n",
    "            legend=False,\n",
    "            style_kwds=focus_style_kwds,\n",
    "        )\n",
    "    else:\n",
    "        if focus_col not in focus_wgs84.columns:\n",
    "            raise ValueError(f\"'{focus_col}' column not found in focus_gdf.\")\n",
    "\n",
    "        focus_wgs84.explore(\n",
    "            m=m,\n",
    "            column=focus_col,\n",
    "            categorical=bool(focus_categorical),\n",
    "            legend=bool(focus_legend),\n",
    "            tooltip=tooltip,\n",
    "            cmap=focus_cmap,\n",
    "            name=focus_name,\n",
    "            style_kwds=focus_style_kwds,\n",
    "        )\n",
    "\n",
    "    # Reference points (optional)\n",
    "    reference_points = parse_reference_points(POIs)\n",
    "    if reference_points:\n",
    "        ref_layer = folium.FeatureGroup(name=\"Reference points\", show=False)\n",
    "        label_layer = folium.FeatureGroup(name=\"Reference point names\", show=False)\n",
    "\n",
    "        for pt in reference_points:\n",
    "            folium.Marker(\n",
    "                [pt[\"lat\"], pt[\"lon\"]],\n",
    "                popup=pt[\"name\"],\n",
    "                tooltip=pt[\"name\"],\n",
    "                icon=folium.Icon(icon=\"info-sign\"),\n",
    "            ).add_to(ref_layer)\n",
    "\n",
    "            folium.Marker(\n",
    "                [pt[\"lat\"], pt[\"lon\"]],\n",
    "                icon=DivIcon(\n",
    "                    html=f\"<div style='font-size:12px;font-weight:600;'>{pt['name']}</div>\"\n",
    "                ),\n",
    "            ).add_to(label_layer)\n",
    "\n",
    "        ref_layer.add_to(m)\n",
    "        label_layer.add_to(m)\n",
    "\n",
    "    folium.LayerControl(collapsed=layer_control_collapsed).add_to(m)\n",
    "\n",
    "    # Fit bounds\n",
    "    if fit_to == \"all\" and context_wgs84 is not None and len(context_wgs84) > 0:\n",
    "        minx, miny, maxx, maxy = context_wgs84.total_bounds\n",
    "    else:\n",
    "        minx, miny, maxx, maxy = focus_wgs84.total_bounds\n",
    "\n",
    "    m.fit_bounds([[miny, minx], [maxy, maxx]], padding=(10, 10))\n",
    "    return m\n",
    "\n",
    "def get_embedding_cols(gdf, pattern=r\"^A\\d+_mean$\"):\n",
    "    \"\"\"\n",
    "    Return embedding column names sorted by numeric index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing embedding variables.\n",
    "    pattern : str, optional\n",
    "        Regular expression pattern used to select embedding columns.\n",
    "        Default matches ``A##_mean`` style columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        Sorted embedding column names.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If no columns match `pattern`.\n",
    "    \"\"\"\n",
    "    cols = [c for c in gdf.columns if re.match(pattern, c)]\n",
    "    if not cols:\n",
    "        raise ValueError(\"No embedding columns found matching pattern like A##_mean.\")\n",
    "    return sorted(cols, key=lambda x: int(re.findall(r\"\\d+\", x)[0]))\n",
    "\n",
    "\n",
    "def closest_lsoas_to_cluster(\n",
    "    gdf,\n",
    "    cluster_number,\n",
    "    n_closest=5,\n",
    "    cluster_col=\"cluster\",\n",
    "    id_cols=(\"LSOA21CD\", \"LSOA21NM\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    Find LSOAs closest to a cluster centroid in embedding space.\n",
    "\n",
    "    Distance is computed as Euclidean distance between each LSOA's embedding\n",
    "    vector and the centroid of the specified cluster. Members of the cluster\n",
    "    are excluded from the returned set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing embedding variables and cluster labels.\n",
    "    cluster_number : int\n",
    "        Cluster label used to define the centroid.\n",
    "    n_closest : int, optional\n",
    "        Number of closest LSOAs to return. Default is 5.\n",
    "    cluster_col : str, optional\n",
    "        Name of the cluster label column. Default is ``\"cluster\"``.\n",
    "    id_cols : tuple of str, optional\n",
    "        Identifier columns to keep if present. Default is\n",
    "        ``(\"LSOA21CD\", \"LSOA21NM\")``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing the closest LSOAs with an added ``\"distance\"``\n",
    "        column and geometry.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `cluster_col` is missing, `n_closest` is invalid, or the cluster\n",
    "        has no members in `gdf`.\n",
    "    \"\"\"\n",
    "    if cluster_col not in gdf.columns:\n",
    "        raise ValueError(f\"'{cluster_col}' column not found.\")\n",
    "    if not isinstance(n_closest, int) or n_closest <= 0:\n",
    "        raise ValueError(\"n_closest must be a positive integer.\")\n",
    "\n",
    "    emb_cols = get_embedding_cols(gdf)\n",
    "\n",
    "    mask = gdf[cluster_col] == cluster_number\n",
    "    if int(mask.sum()) == 0:\n",
    "        raise ValueError(f\"No rows found for {cluster_col} == {cluster_number}.\")\n",
    "\n",
    "    centroid = np.nanmean(gdf.loc[mask, emb_cols].to_numpy(dtype=float), axis=0)\n",
    "\n",
    "    X = gdf[emb_cols].to_numpy(dtype=float)\n",
    "    distances = np.linalg.norm(X - centroid, axis=1)\n",
    "    distances[mask.to_numpy()] = np.inf\n",
    "\n",
    "    available = int((~mask).sum())\n",
    "    n_use = min(n_closest, available)\n",
    "\n",
    "    idx = np.argsort(distances)[:n_use]\n",
    "    out = gdf.iloc[idx].copy()\n",
    "    out[\"distance\"] = distances[idx]\n",
    "    out = out.sort_values(\"distance\")\n",
    "\n",
    "    keep = [c for c in id_cols if c in out.columns] + [cluster_col, \"distance\", \"geometry\"]\n",
    "    return out[[c for c in keep if c in out.columns]]\n",
    "\n",
    "def map_closest_lsoas(\n",
    "    gdf,\n",
    "    cluster_number,\n",
    "    n_closest,\n",
    "    context_gdf=None,\n",
    "    cluster_col=\"cluster\",\n",
    "    tooltip_cols=(\"LSOA21CD\", \"LSOA21NM\", \"distance\"),\n",
    "    fill_opacity=0.6,\n",
    "    weight=2.0,\n",
    "    edge_color=\"black\",\n",
    "    POIs=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the n closest LSOAs to a cluster centroid (in embedding space)\n",
    "    and map them, optionally over a faint context layer.\n",
    "    \"\"\"\n",
    "    closest_gdf = closest_lsoas_to_cluster(\n",
    "        gdf=gdf,\n",
    "        cluster_number=cluster_number,\n",
    "        n_closest=n_closest,\n",
    "        cluster_col=cluster_col,\n",
    "    )\n",
    "\n",
    "    # Rank for colouring/legend\n",
    "    closest_gdf = closest_gdf.copy()\n",
    "    closest_gdf[\"rank\"] = range(1, len(closest_gdf) + 1)\n",
    "\n",
    "    m = make_webmap_general(\n",
    "        focus_gdf=closest_gdf,\n",
    "        focus_col=\"rank\",\n",
    "        focus_name=f\"{len(closest_gdf)} closest LSOAs\",\n",
    "        focus_tooltip_cols=tooltip_cols,\n",
    "        focus_categorical=True,\n",
    "        focus_legend=True,\n",
    "        focus_cmap=\"Set1\",\n",
    "        focus_style_kwds={\n",
    "            \"fillOpacity\": float(fill_opacity),\n",
    "            \"opacity\": 1.0,\n",
    "            \"weight\": float(weight),\n",
    "            \"color\": edge_color,\n",
    "        },\n",
    "        context_gdf=context_gdf,\n",
    "        context_name=\"Context (all LSOAs)\",\n",
    "        context_style_kwds={\n",
    "            \"fillOpacity\": 0.05,\n",
    "            \"opacity\": 0.6,\n",
    "            \"weight\": 0.6,\n",
    "            \"color\": \"grey\",\n",
    "        },\n",
    "        POIs=POIs,\n",
    "        fit_to=\"focus\",\n",
    "        layer_control_collapsed=False,\n",
    "        zoom_start=12,\n",
    "    )\n",
    "\n",
    "    return m, closest_gdf\n",
    "\n",
    "def plot_embedding_distances(\n",
    "    df,\n",
    "    distance_col=\"distance\",\n",
    "    label_col=\"LSOA21NM\",\n",
    "    title=\"Distances of Closest LSOAs in Embedding Space\",\n",
    "    figsize=(9, 4),\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot embedding-space distances in ascending order with attribute labels shown\n",
    "    on a secondary x-axis.\n",
    "\n",
    "    The primary x-axis shows rank (closest to farthest), while the secondary\n",
    "    x-axis displays values from `label_col` rotated at 45 degrees.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame or geopandas.GeoDataFrame\n",
    "        DataFrame containing distance values and labels.\n",
    "    distance_col : str, optional\n",
    "        Column containing embedding-space distances. Default is ``\"distance\"``.\n",
    "    label_col : str, optional\n",
    "        Column used for top x-axis labels. Default is ``\"LSOA21NM\"``.\n",
    "    title : str, optional\n",
    "        Plot title. Default is ``\"Distances of Closest LSOAs in Embedding Space\"``.\n",
    "    figsize : tuple of int, optional\n",
    "        Figure size in inches. Default is ``(9, 4)``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.axes.Axes\n",
    "        Axes object containing the main plot.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `distance_col` or `label_col` is not present in `df`.\n",
    "    \"\"\"\n",
    "    if distance_col not in df.columns:\n",
    "        raise ValueError(f\"'{distance_col}' column not found.\")\n",
    "    if label_col not in df.columns:\n",
    "        raise ValueError(f\"'{label_col}' column not found.\")\n",
    "\n",
    "    # Sort by distance (ascending)\n",
    "    df_sorted = df.sort_values(distance_col).reset_index(drop=True)\n",
    "\n",
    "    x = range(1, len(df_sorted) + 1)\n",
    "    distances = df_sorted[distance_col]\n",
    "    labels = df_sorted[label_col]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Main plot\n",
    "    ax.plot(x, distances, marker=\"o\")\n",
    "    ax.set_xlabel(\"Rank (closest to farthest)\")\n",
    "    ax.set_ylabel(\"Distance to cluster centroid\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Secondary x-axis (top) for labels\n",
    "    ax_top = ax.secondary_xaxis(\"top\")\n",
    "    ax_top.set_xticks(list(x))\n",
    "    ax_top.set_xticklabels(labels, rotation=45, ha=\"left\", fontsize=8)\n",
    "    ax_top.set_xlabel(label_col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb6825-97ff-497f-828c-b63cde74296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "def run_rf_classifier(\n",
    "    data,\n",
    "    y_col,\n",
    "    x_cols,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\",\n",
    "    dropna=True,\n",
    "    treat_y_as_ordered=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train and evaluate a Random Forest classifier with user-specified target and predictors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.DataFrame or geopandas.GeoDataFrame\n",
    "        Input dataset containing `y_col` and `x_cols`.\n",
    "    y_col : str\n",
    "        Dependent (target) variable column name.\n",
    "    x_cols : list of str\n",
    "        Independent (predictor) column names.\n",
    "    test_size : float, optional\n",
    "        Proportion of data used for testing. Default is 0.2.\n",
    "    random_state : int, optional\n",
    "        Random seed for reproducibility. Default is 42.\n",
    "    n_estimators : int, optional\n",
    "        Number of trees in the forest. Default is 500.\n",
    "    n_jobs : int, optional\n",
    "        Number of CPU cores to use. Default is -1 (all cores).\n",
    "    class_weight : str or dict or None, optional\n",
    "        Class weighting strategy for imbalanced data. Default is \"balanced\".\n",
    "    dropna : bool, optional\n",
    "        If True, drop rows with missing values in y or X. Default is True.\n",
    "    treat_y_as_ordered : bool, optional\n",
    "        If True, convert y to an ordered categorical then to integer codes\n",
    "        for modelling. Useful for ordinal targets (e.g., deciles). Default is True.\n",
    "    verbose : bool, optional\n",
    "        If True, print evaluation outputs. Default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Dictionary containing:\n",
    "        - \"model\": fitted RandomForestClassifier\n",
    "        - \"X_train\", \"X_test\", \"y_train\", \"y_test\"\n",
    "        - \"y_pred\": predicted labels for test set\n",
    "        - \"pred_probs\": DataFrame of predicted probabilities (test set)\n",
    "        - \"accuracy\": test accuracy\n",
    "        - \"mae_ordinal\": mean absolute error in label space (if y is numeric-coded)\n",
    "        - \"confusion\": confusion matrix (crosstab)\n",
    "        - \"importances\": Series of feature importances (sorted desc)\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If required columns are missing or if no rows remain after filtering.\n",
    "    \"\"\"\n",
    "    # --- Column checks\n",
    "    missing = [c for c in ([y_col] + list(x_cols)) if c not in data.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    df = data[[y_col] + list(x_cols)].copy()\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No rows available after filtering/dropping missing values.\")\n",
    "\n",
    "    # --- Prepare y and X\n",
    "    y_raw = df[y_col]\n",
    "\n",
    "    if treat_y_as_ordered:\n",
    "        y_cat = pd.Categorical(y_raw, ordered=True)\n",
    "        y = pd.Series(y_cat.codes, index=df.index) + 1  # codes start at 0\n",
    "        y_categories = y_cat.categories\n",
    "    else:\n",
    "        y = y_raw\n",
    "        y_categories = None\n",
    "\n",
    "    X = df[list(x_cols)]\n",
    "\n",
    "    # --- Train/test split (stratify if possible)\n",
    "    stratify = y if y.nunique() > 1 else None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=float(test_size),\n",
    "        random_state=random_state,\n",
    "        stratify=stratify,\n",
    "    )\n",
    "\n",
    "    # --- Model\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=int(n_estimators),\n",
    "        random_state=random_state,\n",
    "        n_jobs=n_jobs,\n",
    "        class_weight=class_weight,\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # --- Predict\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    pred_probs = rf.predict_proba(X_test)\n",
    "    pred_probs_df = pd.DataFrame(pred_probs, columns=rf.classes_, index=X_test.index)\n",
    "\n",
    "    # --- Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Ordinal-ish MAE (only meaningful if y is numeric-coded)\n",
    "    try:\n",
    "        mae_ordinal = (pd.Series(y_pred, index=X_test.index) - pd.Series(y_test, index=X_test.index)).abs().mean()\n",
    "    except Exception:\n",
    "        mae_ordinal = None\n",
    "\n",
    "    confusion = pd.crosstab(\n",
    "        pd.Series(y_test, name=f\"Actual {y_col}\"),\n",
    "        pd.Series(y_pred, name=f\"Predicted {y_col}\"),\n",
    "    )\n",
    "\n",
    "    importances = pd.Series(rf.feature_importances_, index=list(x_cols)).sort_values(ascending=False)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Test accuracy: {acc:.3f}\")\n",
    "        if mae_ordinal is not None:\n",
    "            print(f\"Mean absolute label error: {mae_ordinal:.2f}\")\n",
    "        print(\"\\nConfusion matrix:\")\n",
    "        print(confusion)\n",
    "        print(\"\\nTop 15 feature importances:\")\n",
    "        print(importances.head(15))\n",
    "\n",
    "    return {\n",
    "        \"model\": rf,\n",
    "        \"X_train\": X_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"pred_probs\": pred_probs_df,\n",
    "        \"accuracy\": acc,\n",
    "        \"mae_ordinal\": mae_ordinal,\n",
    "        \"confusion\": confusion,\n",
    "        \"importances\": importances,\n",
    "        \"y_categories\": y_categories,\n",
    "    }\n",
    "\n",
    "def plot_feature_importance(\n",
    "    importances,\n",
    "    top_n=15,\n",
    "    title=\"Top Feature Importances\",\n",
    "    figsize=(6, 5),\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the top N feature importances from a fitted model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    importances : pandas.Series\n",
    "        Feature importances indexed by feature name\n",
    "        (e.g. results[\"importances\"]).\n",
    "    top_n : int, optional\n",
    "        Number of top features to display. Default is 15.\n",
    "    title : str, optional\n",
    "        Plot title. Default is \"Top Feature Importances\".\n",
    "    figsize : tuple of int, optional\n",
    "        Figure size in inches. Default is (6, 5).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.axes.Axes\n",
    "        Axes object containing the plot.\n",
    "    \"\"\"\n",
    "    if not isinstance(importances, pd.Series):\n",
    "        raise ValueError(\"importances must be a pandas Series.\")\n",
    "\n",
    "    top = importances.head(top_n).sort_values(ascending=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    ax.barh(top.index, top.values)\n",
    "    ax.set_xlabel(\"Feature importance\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc61021-4dec-4524-8714-587222df86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1) Classification helper\n",
    "# ----------------------------\n",
    "def classify_for_mapping(\n",
    "    gdf,\n",
    "    col,\n",
    "    scheme=\"quantile\",        # \"quantile\" (default), \"equal\", \"natural\"\n",
    "    k=10,\n",
    "    label_fmt=\"{lo:.2f}–{hi:.2f}\",\n",
    "    min_unique_to_bin=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare a column for mapping. If the column is numeric and has more than\n",
    "    `min_unique_to_bin` unique values, bin into `k` classes using the chosen scheme.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        Input GeoDataFrame.\n",
    "    col : str\n",
    "        Column to prepare.\n",
    "    scheme : {\"quantile\", \"equal\", \"natural\"}, optional\n",
    "        Classification scheme for numeric variables. Default is \"quantile\".\n",
    "    k : int, optional\n",
    "        Number of classes for numeric variables. Default is 10.\n",
    "    label_fmt : str, optional\n",
    "        Label format for numeric class ranges.\n",
    "    min_unique_to_bin : int, optional\n",
    "        Only bin numeric variables when unique values exceed this threshold.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gdf_out : geopandas.GeoDataFrame\n",
    "        Copy of input with an added categorical column (if binned).\n",
    "    mapped_col : str\n",
    "        Name of the column to map (original or derived).\n",
    "    is_categorical : bool\n",
    "        Whether the returned mapped column should be treated as categorical.\n",
    "    \"\"\"\n",
    "    if col not in gdf.columns:\n",
    "        raise ValueError(f\"'{col}' not found in GeoDataFrame.\")\n",
    "\n",
    "    s = gdf[col]\n",
    "    gdf_out = gdf.copy()\n",
    "\n",
    "    # Non-numeric -> treat as categorical as-is\n",
    "    if not pd.api.types.is_numeric_dtype(s):\n",
    "        return gdf_out, col, True\n",
    "\n",
    "    # Numeric: bin only if sufficiently many unique values\n",
    "    n_unique = s.dropna().nunique()\n",
    "    if n_unique <= min_unique_to_bin:\n",
    "        return gdf_out, col, True\n",
    "\n",
    "    s_nonnull = s.dropna()\n",
    "\n",
    "    if scheme == \"quantile\":\n",
    "        bins = pd.qcut(s_nonnull, q=k, duplicates=\"drop\")\n",
    "        cats = bins.cat.categories  # ordered intervals\n",
    "\n",
    "    elif scheme == \"equal\":\n",
    "        bins = pd.cut(s_nonnull, bins=k)\n",
    "        cats = bins.cat.categories  # ordered intervals\n",
    "\n",
    "    elif scheme == \"natural\":\n",
    "        try:\n",
    "            import mapclassify as mc\n",
    "        except ImportError as e:\n",
    "            raise ImportError(\n",
    "                \"Natural breaks requires `mapclassify`. Install with: pip install mapclassify\"\n",
    "            ) from e\n",
    "\n",
    "        classifier = mc.NaturalBreaks(s_nonnull.to_numpy(), k=k)\n",
    "        yb = pd.Series(classifier.yb, index=s_nonnull.index)\n",
    "\n",
    "        edges = np.r_[-np.inf, classifier.bins]\n",
    "        edges[0] = float(s_nonnull.min())\n",
    "\n",
    "        intervals = [pd.Interval(edges[i], edges[i + 1], closed=\"right\")\n",
    "                     for i in range(len(edges) - 1)]\n",
    "        cats = pd.Index(intervals)\n",
    "\n",
    "        bins = pd.Categorical.from_codes(yb.to_numpy(), categories=cats, ordered=True)\n",
    "        bins = pd.Series(bins, index=s_nonnull.index)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"scheme must be one of: 'quantile', 'equal', 'natural'.\")\n",
    "\n",
    "    # Ordered labels derived from interval order (low -> high)\n",
    "    def _label_interval(iv):\n",
    "        return label_fmt.format(lo=iv.left, hi=iv.right)\n",
    "\n",
    "    labels = [_label_interval(iv) for iv in cats]\n",
    "\n",
    "    # Assign labels using category codes to preserve order reliably\n",
    "    mapped = pd.Series(pd.NA, index=s.index, dtype=\"object\")\n",
    "\n",
    "    if scheme in {\"quantile\", \"equal\"}:\n",
    "        codes = bins.cat.codes.to_numpy()  # 0..n_bins-1\n",
    "        mapped.loc[s_nonnull.index] = [labels[c] if c >= 0 else pd.NA for c in codes]\n",
    "    else:\n",
    "        codes = pd.Categorical(bins, categories=cats, ordered=True).codes\n",
    "        mapped.loc[s_nonnull.index] = [labels[c] if c >= 0 else pd.NA for c in codes]\n",
    "\n",
    "    mapped_col = f\"{col}__{scheme}_k{k}\"\n",
    "\n",
    "    # CRITICAL: lock legend/category order explicitly\n",
    "    gdf_out[mapped_col] = pd.Categorical(mapped, categories=labels, ordered=True)\n",
    "\n",
    "    return gdf_out, mapped_col, True\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Two maps side-by-side\n",
    "# ----------------------------\n",
    "def show_two_maps_side_by_side(\n",
    "    gdf,\n",
    "    left_var,\n",
    "    right_var,\n",
    "    tooltip_cols=(),\n",
    "    scheme=\"quantile\",        # default for numeric >10 unique\n",
    "    k=10,                     # always 10 categories by default\n",
    "    min_unique_to_bin=10,     # trigger binning only when >10 unique values\n",
    "    cmap_left=\"YlOrRd_r\",\n",
    "    cmap_right=\"viridis\",\n",
    "    POIs=None,\n",
    "    zoom_start=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Display two Folium maps side by side. For numeric variables with more than\n",
    "    `min_unique_to_bin` unique values, bin into `k` ordered categories using `scheme`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function assumes `make_webmap_general` and `parse_reference_points`\n",
    "    are already defined in the notebook.\n",
    "    \"\"\"\n",
    "    # Left map: classify if needed\n",
    "    g_left, left_mapped, _ = classify_for_mapping(\n",
    "        gdf, left_var, scheme=scheme, k=k, min_unique_to_bin=min_unique_to_bin\n",
    "    )\n",
    "\n",
    "    # Right map: classify if needed\n",
    "    g_right, right_mapped, _ = classify_for_mapping(\n",
    "        gdf, right_var, scheme=scheme, k=k, min_unique_to_bin=min_unique_to_bin\n",
    "    )\n",
    "\n",
    "    # Create maps\n",
    "    m_left = make_webmap_general(\n",
    "        focus_gdf=g_left,\n",
    "        focus_col=left_mapped,\n",
    "        focus_name=left_var,\n",
    "        focus_tooltip_cols=tooltip_cols,\n",
    "        focus_categorical=True,\n",
    "        focus_legend=True,\n",
    "        focus_cmap=cmap_left,\n",
    "        POIs=POIs,\n",
    "        zoom_start=zoom_start,\n",
    "    )\n",
    "\n",
    "    m_right = make_webmap_general(\n",
    "        focus_gdf=g_right,\n",
    "        focus_col=right_mapped,\n",
    "        focus_name=right_var,\n",
    "        focus_tooltip_cols=tooltip_cols,\n",
    "        focus_categorical=True,\n",
    "        focus_legend=True,\n",
    "        focus_cmap=cmap_right,\n",
    "        POIs=POIs,\n",
    "        zoom_start=zoom_start,\n",
    "    )\n",
    "\n",
    "    html = f\"\"\"\n",
    "    <div style=\"display:flex; gap:10px;\">\n",
    "      <div style=\"width:50%;\">{m_left._repr_html_()}</div>\n",
    "      <div style=\"width:50%;\">{m_right._repr_html_()}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f07f61-fb2b-43b8-9908-5dbc67e8c248",
   "metadata": {},
   "source": [
    "# PART 1: Unsupervised classification\n",
    "A method of grouping data into categories without using pre-defined labels, based solely on similarity in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69cfe7-e888-46ac-b11c-9d96bf219860",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Before we can use the data it must first be loaded into our working environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13269c7-6422-4b7f-a8f5-f646242919a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding data\n",
    "gpkg_path = \"/Lab2 data/uk_lsoa_london_embeds_2024.gpkg\"\n",
    "\n",
    "# Save the data into a GeoDataFrame\n",
    "gdf = gpd.read_file(gpkg_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44448909-a696-42ce-830a-7dda1ea58b7b",
   "metadata": {},
   "source": [
    "## Display information about data\n",
    "Let's make sure that data is loaded by trying to display some of its information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130984d4-8be1-41ae-9a13-639098a51c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display coordinate reference system information\n",
    "print(f'The CRS for this dataset is: {gdf.crs}')\n",
    "\n",
    "# Display the first few records of the data\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f643b15-bb08-43ae-a783-03a5c41ced8c",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Looking at the table above, not all variables are useful for this lab. In this step, the dataset is simplified by retaining only the embedding attributes, along with the information needed to identify each LSOA. This focuses subsequent analysis on the embedding information while preserving the spatial geometry for later mapping and interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00a030-600a-4416-b247-b8654b47000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataset with attributes that we want to keep\n",
    "gdf = filter_table(gdf)\n",
    "\n",
    "# Display new datasets\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e7e83-ec40-48dd-b962-53447ed088f9",
   "metadata": {},
   "source": [
    "In the above we can see that attributes like 'dzcode' are not present in the filtered datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a1c3b-cdca-44e1-abfb-5ed99b79825c",
   "metadata": {},
   "source": [
    "## Cluster using k-means\n",
    "An unsupervised algorithm that groups data into a specified number of clusters by minimising the distance between data points and the centre of their assigned cluster.\n",
    "\n",
    "*NOTE:* For kmeans, you have to tell the algorithms how many clusters/groups you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d74b6a-119b-4cd4-b47d-98795d117517",
   "metadata": {},
   "source": [
    "### Lets use 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18708cbc-022c-4fa6-ba19-c80566d946dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER: Enter the number of clusters that you want\n",
    "k = 3\n",
    "\n",
    "# Cluster LSOAs\n",
    "gdf = kmeans_clustering(gdf, k, feature_suffix=\"_mean\", random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c70228-3283-4d03-98a7-03062450d3e7",
   "metadata": {},
   "source": [
    "## Display clusters\n",
    "Let's now have a look at our data again to see if the new cluster labels were added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892247cb-b2b0-4c00-a7c9-e1d8627ff804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display to top 20 rows of the data\n",
    "gdf.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebd6e2-4b24-4d51-ab43-b1a2c544e70f",
   "metadata": {},
   "source": [
    "##### But are there really 3 clusters? Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28aeae6-c079-4bcd-b26e-e64544e933c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cluster_labels(gdf, cluster_col=\"cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219f3c8-e197-4daf-abbd-7c438f7bc6d1",
   "metadata": {},
   "source": [
    "## Show clusters on a map\n",
    "The above is great but displaying the clusters on a map would add a lot more context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeee3a5-4a1c-40c7-9322-91f6e481dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# Plot a map of clusters\n",
    "#------------------------------\n",
    "plot_simple_map(\n",
    "    gdf,\n",
    "    cluster_col=\"cluster\",\n",
    "    title=\"Unsupervised clusters for London LSOAs\",\n",
    "    figsize=(8, 8),\n",
    "    legend=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59e1662-be64-401c-ab78-c9df0277afb7",
   "metadata": {},
   "source": [
    "##### If you want, you can try other values for k (i.e., the number of clusters) and rerun the above code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db0128-3678-489a-916d-36031bb76110",
   "metadata": {},
   "source": [
    "**YOUR TURN:** Try re-runing the code again for different number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf0c7a9-16c7-4b99-8c26-c3dc2e083c34",
   "metadata": {},
   "source": [
    "Let's make the map a bit more usable and interactive. We'll add some reference points to situate ourselves, along with providing a satellite imagery layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21297dfa-390f-4379-8d1f-863dc74bee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER: Add reference points in the format of: \"<Name>\", latitude, longitude\n",
    "POIs = \"\"\"\n",
    "\"Westminster\", 51.4975, -0.1357\n",
    "\"City of London\", 51.5155, -0.0922\n",
    "\"WE ARE HERE :)\", 51.4962, -0.1298\n",
    "\"London Euston Station\", 51.5282, -0.1337\n",
    "\"\"\"\n",
    "\n",
    "# Draws the maps\n",
    "m = make_webmap_general(\n",
    "    focus_gdf=gdf,\n",
    "    focus_col=\"cluster\",\n",
    "    focus_name=\"Clusters\",\n",
    "    focus_tooltip_cols=(\"LSOA21NM\", \"cluster\"),\n",
    "    focus_categorical=True,\n",
    "    focus_legend=True,\n",
    "    focus_cmap=\"Set1\",\n",
    "    focus_style_kwds={\n",
    "        \"fillOpacity\": 0.6,\n",
    "        \"weight\": 0.2,\n",
    "        \"color\": \"black\",\n",
    "    },\n",
    "    context_gdf=None,   # no background layer\n",
    "    POIs=POIs,\n",
    "    fit_to=\"focus\",\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b444b70-bb0f-48c7-a570-009ea697651c",
   "metadata": {},
   "source": [
    "# Identify closest embeddings by cluster\n",
    "One of the advantages of embedding representations is that observations that are closer in the embedding space are more similar in their underlying characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe846e62-740d-4fe2-b9c1-f1e98f658ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER: Enter cluster number to explore\n",
    "cluster_number = 2\n",
    "# USER: Enter the number of closest LSOAs to use\n",
    "n_closest_to_show = 16\n",
    "\n",
    "# Map clusters\n",
    "m, closestN = map_closest_lsoas(\n",
    "    gdf=gdf,\n",
    "    cluster_number=cluster_number,\n",
    "    n_closest=n_closest_to_show,\n",
    "    context_gdf=gdf,\n",
    "    POIs=None,  # optional\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03697e9b-2c45-4b3a-a70a-62ace612ef7d",
   "metadata": {},
   "source": [
    "# View embedding distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e2add-5575-42da-8c27-a9920a4fc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display table with embedding distances\n",
    "closestN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5cd156-b7b7-4067-9839-50f1b071eb06",
   "metadata": {},
   "source": [
    "# Plot embedding distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f2a39-897a-44e4-9d43-afad5a5e411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Plot embedding distance of closest n embeddings\n",
    "#-------------------------------------------------\n",
    "plot_embedding_distances(\n",
    "    closestN,\n",
    "    distance_col=\"distance\",\n",
    "    label_col=\"LSOA21NM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e121dc8-80bc-4208-9e7f-72924e78ab3d",
   "metadata": {},
   "source": [
    "**YOUR TURN**\n",
    "\n",
    "Experiment with different clustering configurations:\n",
    "\n",
    "1. Vary the number of clusters (`k`) used in the unsupervised clustering.\n",
    "2. Select different clusters and explore their spatial distribution.\n",
    "3. Change the number of closest embeddings (`n_closest`) and observe how the set of similar LSOAs expands or contracts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535f499-133d-4470-9d22-161324b368df",
   "metadata": {},
   "source": [
    "# PART 2: Predictive modelling\n",
    "Uses existing data to train a model that estimates or classifies an outcome for new locations, allowing patterns learned from embeddings and other features to be applied beyond the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a942b7-ccb5-438f-99b2-94948e185a5b",
   "metadata": {},
   "source": [
    "## Load socioeconomic data\n",
    "This data contains the Index of Multiple Deprivations (IMD) in deciles and along with some additional variables that have been reported in the literature to influence IMD. IMD deciles divide areas into ten equal groups, with lower deciles indicating higher levels of deprivation and higher deciles indicating lower levels of deprivation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3724f-febf-4d7e-af08-70ec33eaabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('/Lab2 data/Socioeconomic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd732a-cb86-4fca-99b9-cafac70adca0",
   "metadata": {},
   "source": [
    "# Display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b8567-d7fd-4430-85ad-9396eb143fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b19690-2815-414d-9fda-a2cd78583c6f",
   "metadata": {},
   "source": [
    "# Add socioeconomic data to our embedding data\n",
    "We will be using the common attribute 'LSOA21CD' to link both sets of data, that is, our data with the embedding variables and socioeconomic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c8c8a-bde4-481e-b6f3-760d975f5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join both datasets\n",
    "gdf2 = gdf.merge(\n",
    "    df,\n",
    "    on=\"LSOA21CD\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a359ac-62cb-45c2-a1a6-d25c1b273665",
   "metadata": {},
   "source": [
    "# Display updated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b59d1-8898-488b-b15b-783eb61d667e",
   "metadata": {},
   "source": [
    "Check that both sets of data are now together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca7a9f-3966-49da-9e12-5c9af9bf0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display updated data\n",
    "gdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8f1b6-bbff-4fe7-b0ea-cd020cc483c2",
   "metadata": {},
   "source": [
    "# Display the IMD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1bea50-95d1-40b3-a36c-57533f0607bd",
   "metadata": {},
   "source": [
    "Lets see how the data looks on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a54fb-2570-43a7-a1d5-25c5b8a2c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER: You can add more reference point here in the format\n",
    "#       <\"Name of place\">, latitude, longitude\n",
    "\n",
    "POIs = \"\"\"\n",
    "\"Westminster\", 51.4975, -0.1357\n",
    "\"City of London\", 51.5155, -0.0922\n",
    "\"Canary Wharf\", 51.5054, -0.0235\n",
    "\"King's Cross\", 51.5308, -0.1238\n",
    "\"Heathrow Airport\", 51.4700, -0.4543\n",
    "\"WE ARE HERE :)\", 51.4962, -0.1298\n",
    "\"\"\"\n",
    "\n",
    "# Draws the map\n",
    "m = make_webmap_general(\n",
    "    focus_gdf=gdf2,                 # your GeoDataFrame with IMD merged in\n",
    "    focus_col=\"IMD_decile\",         # colour polygons by IMD decile\n",
    "    focus_name=\"LSOA IMD Deciles\",\n",
    "    focus_tooltip_cols=(\"LSOA21CD\", \"LSOA21NM\", \"IMD_decile\"),\n",
    "    focus_categorical=True,         # deciles are categorical/ordinal\n",
    "    focus_legend=True,\n",
    "    focus_cmap=\"YlOrRd_r\",              # good discrete palette\n",
    "    focus_style_kwds={\n",
    "        \"fillOpacity\": 0.6,\n",
    "        \"weight\": 0.2,\n",
    "        \"color\": \"black\",\n",
    "    },\n",
    "    context_gdf=None,               # or set to gdf2 for a faint background (usually unnecessary)\n",
    "    POIs=POIs,\n",
    "    fit_to=\"focus\",\n",
    "    zoom_start=10,\n",
    ")\n",
    "\n",
    "m\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Alternative colour palettes for focus_cmap:\n",
    "\n",
    "Warm / sequential (similar to YlOrRd_r):\n",
    "- \"OrRd\"\n",
    "- \"Reds\"\n",
    "- \"YlGnBu_r\"\n",
    "- \"PuRd\"\n",
    "- \"YlOrBr\"\n",
    "\n",
    "Cool / neutral sequential:\n",
    "- \"Blues\"\n",
    "- \"Greens\"\n",
    "- \"BuGn\"\n",
    "- \"GnBu\"\n",
    "- \"viridis\"\n",
    "\n",
    "Perceptually uniform (publication & accessibility friendly):\n",
    "- \"plasma\"\n",
    "- \"inferno\"\n",
    "- \"magma\"\n",
    "- \"cividis\"\n",
    "\n",
    "Diverging (use only if a meaningful midpoint exists):\n",
    "- \"RdBu_r\"\n",
    "- \"BrBG\"\n",
    "- \"PuOr\"\n",
    "- \"coolwarm\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c6c233-8754-4d54-844b-3109797013dc",
   "metadata": {},
   "source": [
    "# Create a model to predict IMD using ONLY socioeconomic variables\n",
    "We'll used variables that have been identified in previous studies as predictors of IMD, specifically:\n",
    "- Percent no qualifications 16 and over\n",
    "- Percent bad and very band health\n",
    "- Population density per km\n",
    "- Percent lone family household\n",
    "\n",
    "We'll also be using a random forest model, which[link text](https://) is an ensemble of decision trees. It can model non-linear relationships and interactions between predictors without requiring the proportional-odds assumption used by ordinal logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbdc14-8c23-45ff-a009-c1aa3f7b77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the random forest classifiers and return results\n",
    "results = run_rf_classifier(\n",
    "    data=gdf2,\n",
    "    y_col=\"IMD_decile\",\n",
    "    x_cols=[\"Percent no qualifications 16 and over\",\n",
    "            \"Percent bad and very band health\",\n",
    "            \"Population density per km\",\n",
    "            \"Percent lone family household\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c42be-f3a7-4a52-a2f1-16979917efdc",
   "metadata": {},
   "source": [
    "# Create a model to predict IMD using ONLY embedding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220cb86-c06d-40da-8d2d-11c1b21a6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictor variables\n",
    "feature_cols = [f\"A{i:02d}_mean\" for i in range(64)]\n",
    "\n",
    "# Run the random forest classifiers and return results\n",
    "results = run_rf_classifier(\n",
    "    data=gdf2,\n",
    "    y_col=\"IMD_decile\",\n",
    "    x_cols=feature_cols,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    n_estimators=500,\n",
    "    class_weight=\"balanced\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54eb53-5e20-4ce6-b938-73ab086b1c0f",
   "metadata": {},
   "source": [
    "# Create a model to predict IMD using both socioeconomic and embedding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb0761-2837-445d-b4a8-557a8ac04a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictor variables\n",
    "feature_cols = [f\"A{i:02d}_mean\" for i in range(64)] + [\"Percent no qualifications 16 and over\",\n",
    "            \"Percent bad and very band health\",\n",
    "            \"Population density per km\",\n",
    "            \"Percent lone family household\"]\n",
    "\n",
    "# Run the random forest classifiers and return results\n",
    "results = run_rf_classifier(\n",
    "    data=gdf2,\n",
    "    y_col=\"IMD_decile\",\n",
    "    x_cols=feature_cols,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    n_estimators=500,\n",
    "    class_weight=\"balanced\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91602c95-1986-4d55-a9a4-239c888a750a",
   "metadata": {},
   "source": [
    "# Plotting the top 15 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700dcae-4810-41cc-9f70-ac51d3b1e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variable importance\n",
    "plot_feature_importance(\n",
    "    results[\"importances\"],\n",
    "    top_n=15,\n",
    "    title=\"Top 15 Embedding Features Predicting IMD Decile\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc8fd6-ca5e-4892-be0c-d0f43c0d172e",
   "metadata": {},
   "source": [
    "# Compare variables - side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0bae2-0152-443e-bfe7-9fe1ea452c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two maps side by side using 10 quantile levels for comparison.\n",
    "\n",
    "show_two_maps_side_by_side(\n",
    "    gdf2,\n",
    "    left_var=\"IMD_decile\",\n",
    "    right_var=\"Percent no qualifications 16 and over\",\n",
    "    tooltip_cols=(\"LSOA21CD\", \"LSOA21NM\"),\n",
    "    scheme=\"quantile\",\n",
    "    k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee82f7d-e8c0-4c58-8f90-b94eebdc1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two maps side by side using 10 equal-interval levels for comparison.\n",
    "\n",
    "show_two_maps_side_by_side(\n",
    "    gdf2,\n",
    "    left_var=\"IMD_decile\",\n",
    "    right_var=\"Percent no qualifications 16 and over\",\n",
    "    scheme=\"equal\",\n",
    "    k=10,\n",
    "    tooltip_cols=(\"LSOA21NM\",),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70619162-0a2d-4781-ab0a-e695367217ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two maps side by side using 10 natural break levels for comparison.\n",
    "\n",
    "show_two_maps_side_by_side(\n",
    "    gdf2,\n",
    "    left_var=\"IMD_decile\",\n",
    "    right_var=\"Percent no qualifications 16 and over\",\n",
    "    scheme=\"natural\",\n",
    "    k=10,\n",
    "    tooltip_cols=(\"LSOA21NM\",),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da20b0e-5f42-4c8a-9676-0f79c37cb24a",
   "metadata": {},
   "source": [
    "**YOUR TURN:** Choose the most influential embedding variable and visually compare it to the IMD variable to explore their spatial relationship, and briefly interpret any patterns or contrasts observed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
