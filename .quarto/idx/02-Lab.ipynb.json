{"title":"Lab II","markdown":{"yaml":{"title":"Lab II","format":{"html":{"code-fold":true}}},"headingText":"Overview","containsRefs":false,"markdown":"\n\n\n**What is the lab about**?\n\nThis lab provides a practical overview of how satellite image embeddings can be used as a general-purpose spatial representation.\n\nThe lab begins with unsupervised analysis, where participants use embeddings to explore and structure geographic space without predefined labels. This demonstrates how embeddings support exploratory analysis and place-based typologies. The same embeddings are then reused in a predictive context, showing how a single representation can support multiple analytical tasks without rebuilding the feature pipeline.\n\nThe emphasis throughout is on reusability and judgement:\n\n* how embeddings enable faster exploration.\n* how they integrate into standard analytical workflows, and\n* when they meaningfully improve predictive performance.\n  \nThe lab is not about training complex models, but about understanding how and when embeddings add value as spatial evidence.\n\n# Learning outcomes\n\nBy the end of the lab, participants will be able to:\n\n- Interpret satellite image embeddings as spatial representations.\n- Build and evaluate unsupervised place typologies.\n- Build and evauluate predictive models using embeddings.\n- Judge when embeddings improve geospatial evidence.\n\n# Data\n\n#### Embedding data\n\n- Google satellite image embedding data for London (2024).\n- Embeddings are aggregated to the Lower-layer Super Output Area (LSOA) level using the mean value of each embedding dimension.\n- The final dataset contains 64 embedding variables (A00_mean to A63_mean) and is provided as a GeoPackage:\n  `uk_lsoa_london_embeds_2024.gpkg`\n\n\n#### Socio-demographic data\n\n- **Index of Multiple Deprivation (IMD)**\n  - The Index of Multiple Deprivation (IMD) 2025 for England provides a relative measure of deprivation across 32,844 Lower-layer Super Output Areas (LSOAs).\n  - Deprivation is reported in deciles, representing 10% bands from most to least deprived.\n  - Data are available from the Ministry of Housing, Communities and Local Government GeoPortal:\n    https://communitiesopendata-communities.hub.arcgis.com/\n\n\n- **Socio-economic and population characteristics**\n  - Percentage of the population aged 16 years and over with no educational qualifications.\n  - Percentage of the population reporting bad or very bad health.\n  - Population density (persons per km²).\n  - Percentage of single-parent households.\n  - Data sourced from the 2021 Census via NOMIS:\n    https://www.nomisweb.co.uk/sources/census_2021_bulk\n\n- Both sets of data have been linked by their LSOA id and placed into 'Socioeconomic.csv'.\n\n## Import libraries\nBefore working with the data, a number of Python libraries are required to support data handling, spatial analysis, and modelling tasks in this lab.\n\nThese libraries provide functionality for:\n\n- reading and manipulating tabular and spatial data.\n- performing numerical and statistical operations.\n- visualising spatial patterns, and\n- applying clustering and predictive models.\n\nAll code in this lab assumes that these libraries are available in the working environment and correctly imported before proceeding to the analytical steps.\n\n# Functions\nThese are reusable blocks of code that perform a specific task throughout the lab.\n\n# PART 1: Unsupervised classification\nA method of grouping data into categories without using pre-defined labels, based solely on similarity in the data.\n\n## Load data\nBefore we can use the data it must first be loaded into our working environment.\n\n## Display information about data\nLet's make sure that data is loaded by trying to display some of its information.\n\n## Preprocessing\nLooking at the table above, not all variables are useful for this lab. In this step, the dataset is simplified by retaining only the embedding attributes, along with the information needed to identify each LSOA. This focuses subsequent analysis on the embedding information while preserving the spatial geometry for later mapping and interpretation.\n\nIn the above we can see that attributes like 'dzcode' are not present in the filtered datasets\n\n## Cluster using k-means\nAn unsupervised algorithm that groups data into a specified number of clusters by minimising the distance between data points and the centre of their assigned cluster.\n\n*NOTE:* For kmeans, you have to tell the algorithms how many clusters/groups you want.\n\n### Lets use 3 clusters\n\n## Display clusters\nLet's now have a look at our data again to see if the new cluster labels were added.\n\n##### But are there really 3 clusters? Let's check.\n\n## Show clusters on a map\nThe above is great but displaying the clusters on a map would add a lot more context.\n\n##### If you want, you can try other values for k (i.e., the number of clusters) and rerun the above code\n\n**YOUR TURN:** Try re-runing the code again for different number of clusters.\n\nLet's make the map a bit more usable and interactive. We'll add some reference points to situate ourselves, along with providing a satellite imagery layer.\n\n# Identify closest embeddings by cluster\nOne of the advantages of embedding representations is that observations that are closer in the embedding space are more similar in their underlying characteristics.\n\n# View embedding distances\n\n# Plot embedding distances\n\n**YOUR TURN**\n\nExperiment with different clustering configurations:\n\n1. Vary the number of clusters (`k`) used in the unsupervised clustering.\n2. Select different clusters and explore their spatial distribution.\n3. Change the number of closest embeddings (`n_closest`) and observe how the set of similar LSOAs expands or contracts.\n\n\n# PART 2: Predictive modelling\nUses existing data to train a model that estimates or classifies an outcome for new locations, allowing patterns learned from embeddings and other features to be applied beyond the observed data.\n\n## Load socioeconomic data\nThis data contains the Index of Multiple Deprivations (IMD) in deciles and along with some additional variables that have been reported in the literature to influence IMD. IMD deciles divide areas into ten equal groups, with lower deciles indicating higher levels of deprivation and higher deciles indicating lower levels of deprivation.\n\n# Display the data\n\n# Add socioeconomic data to our embedding data\nWe will be using the common attribute 'LSOA21CD' to link both sets of data, that is, our data with the embedding variables and socioeconomic variables.\n\n# Display updated data\n\nCheck that both sets of data are now together.\n\n# Display the IMD data\n\nLets see how the data looks on a map.\n\n# Create a model to predict IMD using ONLY socioeconomic variables\nWe'll used variables that have been identified in previous studies as predictors of IMD, specifically:\n- Percent no qualifications 16 and over\n- Percent bad and very band health\n- Population density per km\n- Percent lone family household\n\nWe'll also be using a random forest model, which[link text](https://) is an ensemble of decision trees. It can model non-linear relationships and interactions between predictors without requiring the proportional-odds assumption used by ordinal logistic regression.\n\n# Create a model to predict IMD using ONLY embedding variables\n\n# Create a model to predict IMD using both socioeconomic and embedding variables\n\n# Plotting the top 15 variables\n\n# Compare variables - side by side\n\n**YOUR TURN:** Choose the most influential embedding variable and visually compare it to the IMD variable to explore their spatial relationship, and briefly interpret any patterns or contrasts observed.\n","srcMarkdownNoYaml":"\n\n# Overview\n\n**What is the lab about**?\n\nThis lab provides a practical overview of how satellite image embeddings can be used as a general-purpose spatial representation.\n\nThe lab begins with unsupervised analysis, where participants use embeddings to explore and structure geographic space without predefined labels. This demonstrates how embeddings support exploratory analysis and place-based typologies. The same embeddings are then reused in a predictive context, showing how a single representation can support multiple analytical tasks without rebuilding the feature pipeline.\n\nThe emphasis throughout is on reusability and judgement:\n\n* how embeddings enable faster exploration.\n* how they integrate into standard analytical workflows, and\n* when they meaningfully improve predictive performance.\n  \nThe lab is not about training complex models, but about understanding how and when embeddings add value as spatial evidence.\n\n# Learning outcomes\n\nBy the end of the lab, participants will be able to:\n\n- Interpret satellite image embeddings as spatial representations.\n- Build and evaluate unsupervised place typologies.\n- Build and evauluate predictive models using embeddings.\n- Judge when embeddings improve geospatial evidence.\n\n# Data\n\n#### Embedding data\n\n- Google satellite image embedding data for London (2024).\n- Embeddings are aggregated to the Lower-layer Super Output Area (LSOA) level using the mean value of each embedding dimension.\n- The final dataset contains 64 embedding variables (A00_mean to A63_mean) and is provided as a GeoPackage:\n  `uk_lsoa_london_embeds_2024.gpkg`\n\n\n#### Socio-demographic data\n\n- **Index of Multiple Deprivation (IMD)**\n  - The Index of Multiple Deprivation (IMD) 2025 for England provides a relative measure of deprivation across 32,844 Lower-layer Super Output Areas (LSOAs).\n  - Deprivation is reported in deciles, representing 10% bands from most to least deprived.\n  - Data are available from the Ministry of Housing, Communities and Local Government GeoPortal:\n    https://communitiesopendata-communities.hub.arcgis.com/\n\n\n- **Socio-economic and population characteristics**\n  - Percentage of the population aged 16 years and over with no educational qualifications.\n  - Percentage of the population reporting bad or very bad health.\n  - Population density (persons per km²).\n  - Percentage of single-parent households.\n  - Data sourced from the 2021 Census via NOMIS:\n    https://www.nomisweb.co.uk/sources/census_2021_bulk\n\n- Both sets of data have been linked by their LSOA id and placed into 'Socioeconomic.csv'.\n\n## Import libraries\nBefore working with the data, a number of Python libraries are required to support data handling, spatial analysis, and modelling tasks in this lab.\n\nThese libraries provide functionality for:\n\n- reading and manipulating tabular and spatial data.\n- performing numerical and statistical operations.\n- visualising spatial patterns, and\n- applying clustering and predictive models.\n\nAll code in this lab assumes that these libraries are available in the working environment and correctly imported before proceeding to the analytical steps.\n\n# Functions\nThese are reusable blocks of code that perform a specific task throughout the lab.\n\n# PART 1: Unsupervised classification\nA method of grouping data into categories without using pre-defined labels, based solely on similarity in the data.\n\n## Load data\nBefore we can use the data it must first be loaded into our working environment.\n\n## Display information about data\nLet's make sure that data is loaded by trying to display some of its information.\n\n## Preprocessing\nLooking at the table above, not all variables are useful for this lab. In this step, the dataset is simplified by retaining only the embedding attributes, along with the information needed to identify each LSOA. This focuses subsequent analysis on the embedding information while preserving the spatial geometry for later mapping and interpretation.\n\nIn the above we can see that attributes like 'dzcode' are not present in the filtered datasets\n\n## Cluster using k-means\nAn unsupervised algorithm that groups data into a specified number of clusters by minimising the distance between data points and the centre of their assigned cluster.\n\n*NOTE:* For kmeans, you have to tell the algorithms how many clusters/groups you want.\n\n### Lets use 3 clusters\n\n## Display clusters\nLet's now have a look at our data again to see if the new cluster labels were added.\n\n##### But are there really 3 clusters? Let's check.\n\n## Show clusters on a map\nThe above is great but displaying the clusters on a map would add a lot more context.\n\n##### If you want, you can try other values for k (i.e., the number of clusters) and rerun the above code\n\n**YOUR TURN:** Try re-runing the code again for different number of clusters.\n\nLet's make the map a bit more usable and interactive. We'll add some reference points to situate ourselves, along with providing a satellite imagery layer.\n\n# Identify closest embeddings by cluster\nOne of the advantages of embedding representations is that observations that are closer in the embedding space are more similar in their underlying characteristics.\n\n# View embedding distances\n\n# Plot embedding distances\n\n**YOUR TURN**\n\nExperiment with different clustering configurations:\n\n1. Vary the number of clusters (`k`) used in the unsupervised clustering.\n2. Select different clusters and explore their spatial distribution.\n3. Change the number of closest embeddings (`n_closest`) and observe how the set of similar LSOAs expands or contracts.\n\n\n# PART 2: Predictive modelling\nUses existing data to train a model that estimates or classifies an outcome for new locations, allowing patterns learned from embeddings and other features to be applied beyond the observed data.\n\n## Load socioeconomic data\nThis data contains the Index of Multiple Deprivations (IMD) in deciles and along with some additional variables that have been reported in the literature to influence IMD. IMD deciles divide areas into ten equal groups, with lower deciles indicating higher levels of deprivation and higher deciles indicating lower levels of deprivation.\n\n# Display the data\n\n# Add socioeconomic data to our embedding data\nWe will be using the common attribute 'LSOA21CD' to link both sets of data, that is, our data with the embedding variables and socioeconomic variables.\n\n# Display updated data\n\nCheck that both sets of data are now together.\n\n# Display the IMD data\n\nLets see how the data looks on a map.\n\n# Create a model to predict IMD using ONLY socioeconomic variables\nWe'll used variables that have been identified in previous studies as predictors of IMD, specifically:\n- Percent no qualifications 16 and over\n- Percent bad and very band health\n- Population density per km\n- Percent lone family household\n\nWe'll also be using a random forest model, which[link text](https://) is an ensemble of decision trees. It can model non-linear relationships and interactions between predictors without requiring the proportional-odds assumption used by ordinal logistic regression.\n\n# Create a model to predict IMD using ONLY embedding variables\n\n# Create a model to predict IMD using both socioeconomic and embedding variables\n\n# Plotting the top 15 variables\n\n# Compare variables - side by side\n\n**YOUR TURN:** Choose the most influential embedding variable and visually compare it to the IMD variable to explore their spatial relationship, and briefly interpret any patterns or contrasts observed.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","include-in-header":[{"text":"<script defer src=\"https://events.imago.ac.uk/script.js\" data-website-id=\"1d384e7c-c043-45bd-9404-abb364ffe9e0\"></script>\n"}],"output-file":"02-Lab.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","editor":"visual","url":"https://imago-sdruk.github.io/EMBED2Social-Workshop-2026/","theme":["cosmo","assets/imago.scss"],"title":"Lab II"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}